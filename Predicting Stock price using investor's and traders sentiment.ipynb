{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis for stock price prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data collection and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tiwar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tiwar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "# import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import LSTM, Activation, Dropout, Dense, Input, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "import string\n",
    "import re\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow.keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\tiwar\\Downloads\\StockTwits_Mar-Jun.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-415-621b8b2919f5>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Bullish    51231\n",
       "Bearish    18231\n",
       "Name: senti, dtype: int64"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 0','id'],axis=1,inplace=True)\n",
    "data = df[df['senti']!=\" \"]\n",
    "data.dropna(inplace=True)\n",
    "data['senti'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned_text(data):\n",
    "    data.dropna(inplace=True)\n",
    "\n",
    "    def de_emojify(string):\n",
    "        tweet = emoji.demojize(string)\n",
    "        tweet = tweet.replace(\":\", \" \")\n",
    "        tweet = ' '.join(tweet.split())\n",
    "        return tweet\n",
    "\n",
    "    def remove_urls(vTEXT):\n",
    "        vTEXT = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', vTEXT, flags=re.MULTILINE)\n",
    "        return (vTEXT)\n",
    "\n",
    "    def remove_tags(string):\n",
    "        result = re.sub('<.*?>', '', string)\n",
    "        return result\n",
    "\n",
    "    def remove_tags1(string):\n",
    "        result = re.sub(r'[^\\w\\s]', ' ', string)\n",
    "        return result\n",
    "\n",
    "    def remove_punctuations(string):\n",
    "        result = ' '.join(re.sub(r\"[\\.\\,\\!\\?\\:\\;\\-\\=]\", \" \", string).split())\n",
    "        return result\n",
    "\n",
    "    data['body'] = data['body'].apply(lambda cw: de_emojify(cw))\n",
    "    data['length'] = data['body'].apply(lambda x: len(x.split()))\n",
    "    data['body'] = data['body'].apply(lambda cw: remove_tags(cw))\n",
    "    data['body']= data['body'].apply(lambda cw : remove_tags1(cw))\n",
    "    data['body'] = data['body'].apply(lambda cw: remove_punctuations(cw))\n",
    "    data.dropna(inplace=True)\n",
    "    data['body'] = data['body'].str.lower()\n",
    "    data['tokenized body'] = data['body'].apply(nltk.word_tokenize).tolist()\n",
    "    data = data[data['length']>3]\n",
    "    data['body'] = data['body'].apply(lambda x:x.replace('AAPL',''))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-416-27ad528c28bc>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(inplace=True)\n",
      "<ipython-input-416-27ad528c28bc>:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['body'] = data['body'].apply(lambda cw: de_emojify(cw))\n",
      "<ipython-input-416-27ad528c28bc>:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['length'] = data['body'].apply(lambda x: len(x.split()))\n",
      "<ipython-input-416-27ad528c28bc>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['body'] = data['body'].apply(lambda cw: remove_tags(cw))\n",
      "<ipython-input-416-27ad528c28bc>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['body']= data['body'].apply(lambda cw : remove_tags1(cw))\n",
      "<ipython-input-416-27ad528c28bc>:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['body'] = data['body'].apply(lambda cw: remove_punctuations(cw))\n",
      "<ipython-input-416-27ad528c28bc>:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(inplace=True)\n",
      "<ipython-input-416-27ad528c28bc>:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['body'] = data['body'].str.lower()\n",
      "<ipython-input-416-27ad528c28bc>:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['tokenized body'] = data['body'].apply(nltk.word_tokenize).tolist()\n",
      "<ipython-input-416-27ad528c28bc>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['body'] = data['body'].apply(lambda x:x.replace('AAPL',''))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>body</th>\n",
       "      <th>senti</th>\n",
       "      <th>length</th>\n",
       "      <th>tokenized body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-04 22:41:36+00:00</td>\n",
       "      <td>aapl people please get serious on your pt s wi...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>53</td>\n",
       "      <td>[aapl, people, please, get, serious, on, your,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-04 22:42:50+00:00</td>\n",
       "      <td>aapl daily divergence on the daily will it rev...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>18</td>\n",
       "      <td>[aapl, daily, divergence, on, the, daily, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-03-04 22:43:08+00:00</td>\n",
       "      <td>aapl watch video if you want to know what this...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>18</td>\n",
       "      <td>[aapl, watch, video, if, you, want, to, know, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-03-04 22:43:47+00:00</td>\n",
       "      <td>aapl yo man 150 pt</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>5</td>\n",
       "      <td>[aapl, yo, man, 150, pt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-03-04 22:45:05+00:00</td>\n",
       "      <td>aapl i demand free housing in the spaceship to...</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>17</td>\n",
       "      <td>[aapl, i, demand, free, housing, in, the, spac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  created_at  \\\n",
       "0  2021-03-04 22:41:36+00:00   \n",
       "1  2021-03-04 22:42:50+00:00   \n",
       "2  2021-03-04 22:43:08+00:00   \n",
       "5  2021-03-04 22:43:47+00:00   \n",
       "8  2021-03-04 22:45:05+00:00   \n",
       "\n",
       "                                                body    senti  length  \\\n",
       "0  aapl people please get serious on your pt s wi...  Bullish      53   \n",
       "1  aapl daily divergence on the daily will it rev...  Bullish      18   \n",
       "2  aapl watch video if you want to know what this...  Bullish      18   \n",
       "5                                 aapl yo man 150 pt  Bullish       5   \n",
       "8  aapl i demand free housing in the spaceship to...  Bullish      17   \n",
       "\n",
       "                                      tokenized body  \n",
       "0  [aapl, people, please, get, serious, on, your,...  \n",
       "1  [aapl, daily, divergence, on, the, daily, will...  \n",
       "2  [aapl, watch, video, if, you, want, to, know, ...  \n",
       "5                           [aapl, yo, man, 150, pt]  \n",
       "8  [aapl, i, demand, free, housing, in, the, spac...  "
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = cleaned_text(data)\n",
    "data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['Bearish', 'Bullish'], dtype=object), array([3347, 9366], dtype=int64))"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_tokenized = data_1['body'].apply(nltk.word_tokenize).tolist()\n",
    "X_train, X_test,Y_train, Y_test = train_test_split(reviews_tokenized, data_1['senti'], test_size=0.2, random_state = 45)\n",
    "np.unique(Y_test,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(list(map(lambda x: 1 if x==\"Bullish\" else 0, Y_train)))\n",
    "Y_test = np.array(list(map(lambda x: 1 if x==\"Bullish\" else 0, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer(data):\n",
    "    data = np.array(data, dtype=object)\n",
    "    tokenizer = Tokenizer(num_words=20000)\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_index = tokenizer.word_index\n",
    "maxLen = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "# cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "####LSTM\n",
    "model = keras.Sequential()\n",
    "#Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "#model.add(layers.Embedding(embedding_matrix_ft.shape[0], embedding_matrix_ft.shape[1],weights=[embedding_matrix_ft], input_length=maxLen))\n",
    "model.add(layers.Embedding(max_features, 32))\n",
    "model.add(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(layers.Dense(1, activation='sigmoid', kernel_regularizer='l2'))\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_model_prediction (text, tokenizer):\n",
    "    X_test_indices = tokenizer.texts_to_sequences(text)\n",
    "    X_test_indices = pad_sequences(X_test_indices, maxlen=maxLen, padding='post')\n",
    "    return X_test_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = get_data_for_model_prediction(X_train,tokenizer)\n",
    "X_train_indices.shape\n",
    "X_test_indices = get_data_for_model_prediction(X_test,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64\n",
      "159/159 [==============================] - 84s 531ms/step - loss: 0.6156 - accuracy: 0.7418 - val_loss: 0.5959 - val_accuracy: 0.7357\n",
      "Epoch 2/64\n",
      "159/159 [==============================] - 87s 546ms/step - loss: 0.5877 - accuracy: 0.7420 - val_loss: 0.5917 - val_accuracy: 0.7357\n",
      "Epoch 3/64\n",
      "159/159 [==============================] - 86s 541ms/step - loss: 0.5835 - accuracy: 0.7420 - val_loss: 0.5874 - val_accuracy: 0.7357\n",
      "Epoch 4/64\n",
      "159/159 [==============================] - 91s 570ms/step - loss: 0.5770 - accuracy: 0.7427 - val_loss: 0.5544 - val_accuracy: 0.7384\n",
      "Epoch 5/64\n",
      "159/159 [==============================] - 87s 550ms/step - loss: 0.4549 - accuracy: 0.8002 - val_loss: 0.4179 - val_accuracy: 0.8237\n",
      "Epoch 6/64\n",
      "159/159 [==============================] - 85s 536ms/step - loss: 0.3782 - accuracy: 0.8426 - val_loss: 0.3861 - val_accuracy: 0.8359\n",
      "Epoch 7/64\n",
      "159/159 [==============================] - 90s 567ms/step - loss: 0.3497 - accuracy: 0.8568 - val_loss: 0.3857 - val_accuracy: 0.8407\n",
      "Epoch 8/64\n",
      "159/159 [==============================] - 86s 540ms/step - loss: 0.3318 - accuracy: 0.8648 - val_loss: 0.3788 - val_accuracy: 0.8421\n",
      "Epoch 9/64\n",
      "159/159 [==============================] - 86s 539ms/step - loss: 0.3172 - accuracy: 0.8716 - val_loss: 0.3731 - val_accuracy: 0.8453\n",
      "Epoch 10/64\n",
      "159/159 [==============================] - 87s 549ms/step - loss: 0.3069 - accuracy: 0.8772 - val_loss: 0.3742 - val_accuracy: 0.8442\n",
      "Epoch 11/64\n",
      "159/159 [==============================] - 88s 554ms/step - loss: 0.2976 - accuracy: 0.8813 - val_loss: 0.3847 - val_accuracy: 0.8450\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2666529c370>"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 64\n",
    "BATCH = 256\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train_indices, Y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 84.76%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test_indices, Y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Sentiment Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\tiwar\\Downloads\\StockteTwits_AAPl_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Unnamed: 0','id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-416-27ad528c28bc>:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['body'] = data['body'].apply(lambda x:x.replace('AAPL',''))\n"
     ]
    }
   ],
   "source": [
    "df_new = cleaned_text(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = df_new['body']\n",
    "data_for_prediction = get_data_for_model_prediction(cleaned_data, tokenizer)\n",
    "prediction = model.predict(data_for_prediction, batch_size=64)\n",
    "df_new['score'] = prediction\n",
    "#df['senti'] = df['senti'].str.replace('Bearish','negative')\n",
    "#df['senti'] = df['senti'].str.replace('Bullish','positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_new[df_new['senti']!=\" \"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing on 1 year data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-437-048f58f155c8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['label'] = np.array(list(map(lambda x : 'Bullish' if x > 0.50 else 'Bearish',df_test['score'])))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8405037637521714"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'] = np.array(list(map(lambda x : 'Bullish' if x > 0.50 else 'Bearish',df_test['score'])))\n",
    "df_test['label'].head()\n",
    "df_test['senti'].head()\n",
    "import sklearn\n",
    "sklearn.metrics.accuracy_score(df_test['senti'], df_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['senti_true'] = df_new['senti']\n",
    "df_new['senti'] = np.array(list(map(lambda x : 'positive' if x > 0.50 else 'negative',df_new['score'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #Aggregating data on daliy level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-440-688c1ba50b28>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_final['body'][i] = df_test_2['body'][i] + df_test['body'][i]\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "df_new['created_at'] = df_new['created_at'].apply(lambda x:datetime.datetime.strptime(x, '%Y-%m-%d %H:%M:%S+00:00'))\n",
    "df_new['Hour'] = df_new['created_at'].apply(lambda x:x.hour)\n",
    "df_new['Month'] = df_new['created_at'].apply(lambda x:x.month)\n",
    "df_new['Year'] = df_new['created_at'].apply(lambda x:x.year)\n",
    "df_new['weekday'] = df_new['created_at'].apply(lambda x: x.weekday())\n",
    "df_new['day'] = df_new['created_at'].apply(lambda x: x.day)\n",
    "df_new['Date'] = pd.to_datetime(df['created_at']).dt.date\n",
    "\n",
    "\n",
    "df_current = df_new[ (df_new['Hour'] < 16)]\n",
    "df_current_2 = df_new[(df_new['Hour'] > 16)]\n",
    "\n",
    "df_pos_1 = df_current[(df_current['senti']=='positive')]\n",
    "df_pos_1 = df_pos_1.groupby(['Year','Month','day','weekday','Date'])['body'].count().reset_index()\n",
    "df_pos_2 = df_current_2[(df_current_2['senti']=='positive')]\n",
    "df_pos_2 = df_pos_2.groupby(['Year','Month','day','weekday','Date'])['body'].count().reset_index()\n",
    "\n",
    "df_test = df_current.groupby(['Year','Month','day','weekday','Date'])['body'].count().reset_index()\n",
    "df_final = df_test.copy(deep=True)\n",
    "df_test_2 = df_current_2.groupby(['Year','Month','day','weekday','Date'])['body'].count().reset_index()\n",
    "df_sum = df_current.groupby(['Year','Month','day','weekday','Date'])['score'].sum().reset_index()\n",
    "df_sum_2 = df_current_2.groupby(['Year','Month','day','weekday','Date'])['score'].sum().reset_index()\n",
    "total_sum =[]\n",
    "count =0\n",
    "pos_count =[]\n",
    "for i in range(len(df_test)):\n",
    "    df_final['body'][i] = df_test_2['body'][i] + df_test['body'][i]\n",
    "    total_sum.append(df_sum_2['score'][i] + df_sum['score'][i])\n",
    "    pos_count.append(df_pos_2['body'][i] + df_pos_1['body'][i])\n",
    "\n",
    "df_final['total_score'] = total_sum\n",
    "df_final['average_score'] = df_final['total_score']/df_final['body']\n",
    "df_final['pos_count'] = pos_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>Date</th>\n",
       "      <th>body</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>pos_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>619</td>\n",
       "      <td>486.633606</td>\n",
       "      <td>0.786161</td>\n",
       "      <td>519</td>\n",
       "      <td>0.838449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>765</td>\n",
       "      <td>569.742188</td>\n",
       "      <td>0.744761</td>\n",
       "      <td>614</td>\n",
       "      <td>0.802614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>600</td>\n",
       "      <td>444.131714</td>\n",
       "      <td>0.740220</td>\n",
       "      <td>470</td>\n",
       "      <td>0.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-06-20</td>\n",
       "      <td>722</td>\n",
       "      <td>540.997009</td>\n",
       "      <td>0.749303</td>\n",
       "      <td>564</td>\n",
       "      <td>0.781163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>251</td>\n",
       "      <td>187.757950</td>\n",
       "      <td>0.748040</td>\n",
       "      <td>194</td>\n",
       "      <td>0.772908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  day  weekday        Date  body  total_score  average_score  \\\n",
       "0  2020      6   17        2  2020-06-17   619   486.633606       0.786161   \n",
       "1  2020      6   18        3  2020-06-18   765   569.742188       0.744761   \n",
       "2  2020      6   19        4  2020-06-19   600   444.131714       0.740220   \n",
       "3  2020      6   20        5  2020-06-20   722   540.997009       0.749303   \n",
       "4  2020      6   21        6  2020-06-21   251   187.757950       0.748040   \n",
       "\n",
       "   pos_count  pos_prop  \n",
       "0        519  0.838449  \n",
       "1        614  0.802614  \n",
       "2        470  0.783333  \n",
       "3        564  0.781163  \n",
       "4        194  0.772908  "
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['pos_prop'] = df_final['pos_count']/df_final['body']\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Stocks data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_info = pd.read_csv(r'C:\\Users\\tiwar\\Downloads\\tickerdf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_info['Date'] = pd.to_datetime(stocks_info['Date'], infer_datetime_format=False).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(stocks_info['Date'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging stocks and sentiment data for final analysis and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.merge(stocks_info,how = 'outer',left_on='Date', right_on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>Date</th>\n",
       "      <th>body</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>pos_prop</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>619</td>\n",
       "      <td>486.633606</td>\n",
       "      <td>0.786161</td>\n",
       "      <td>519</td>\n",
       "      <td>0.838449</td>\n",
       "      <td>88.193247</td>\n",
       "      <td>88.255328</td>\n",
       "      <td>87.185041</td>\n",
       "      <td>87.309204</td>\n",
       "      <td>114406400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>765</td>\n",
       "      <td>569.742188</td>\n",
       "      <td>0.744761</td>\n",
       "      <td>614</td>\n",
       "      <td>0.802614</td>\n",
       "      <td>87.264512</td>\n",
       "      <td>87.771101</td>\n",
       "      <td>86.720676</td>\n",
       "      <td>87.343979</td>\n",
       "      <td>96820400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>600</td>\n",
       "      <td>444.131714</td>\n",
       "      <td>0.740220</td>\n",
       "      <td>470</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>88.066604</td>\n",
       "      <td>88.543387</td>\n",
       "      <td>85.709978</td>\n",
       "      <td>86.844833</td>\n",
       "      <td>264476000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-06-20</td>\n",
       "      <td>722</td>\n",
       "      <td>540.997009</td>\n",
       "      <td>0.749303</td>\n",
       "      <td>564</td>\n",
       "      <td>0.781163</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>251</td>\n",
       "      <td>187.757950</td>\n",
       "      <td>0.748040</td>\n",
       "      <td>194</td>\n",
       "      <td>0.772908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  day  weekday        Date  body  total_score  average_score  \\\n",
       "0  2020      6   17        2  2020-06-17   619   486.633606       0.786161   \n",
       "1  2020      6   18        3  2020-06-18   765   569.742188       0.744761   \n",
       "2  2020      6   19        4  2020-06-19   600   444.131714       0.740220   \n",
       "3  2020      6   20        5  2020-06-20   722   540.997009       0.749303   \n",
       "4  2020      6   21        6  2020-06-21   251   187.757950       0.748040   \n",
       "\n",
       "   pos_count  pos_prop       Open       High        Low      Close  \\\n",
       "0        519  0.838449  88.193247  88.255328  87.185041  87.309204   \n",
       "1        614  0.802614  87.264512  87.771101  86.720676  87.343979   \n",
       "2        470  0.783333  88.066604  88.543387  85.709978  86.844833   \n",
       "3        564  0.781163        NaN        NaN        NaN        NaN   \n",
       "4        194  0.772908        NaN        NaN        NaN        NaN   \n",
       "\n",
       "        Volume  Dividends  Stock Splits  \n",
       "0  114406400.0        0.0           0.0  \n",
       "1   96820400.0        0.0           0.0  \n",
       "2  264476000.0        0.0           0.0  \n",
       "3          NaN        NaN           NaN  \n",
       "4          NaN        NaN           NaN  "
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>∆t</th>\n",
       "      <th>Month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>Date</th>\n",
       "      <th>body</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>pos_prop</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>trend</th>\n",
       "      <th>seasonal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>619</td>\n",
       "      <td>486.633606</td>\n",
       "      <td>0.786161</td>\n",
       "      <td>519</td>\n",
       "      <td>0.838449</td>\n",
       "      <td>88.193247</td>\n",
       "      <td>88.255328</td>\n",
       "      <td>87.185041</td>\n",
       "      <td>87.309204</td>\n",
       "      <td>1.144064e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.776451</td>\n",
       "      <td>0.068787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>765</td>\n",
       "      <td>569.742188</td>\n",
       "      <td>0.744761</td>\n",
       "      <td>614</td>\n",
       "      <td>0.802614</td>\n",
       "      <td>87.264512</td>\n",
       "      <td>87.771101</td>\n",
       "      <td>86.720676</td>\n",
       "      <td>87.343979</td>\n",
       "      <td>9.682040e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.980214</td>\n",
       "      <td>-0.091560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>600</td>\n",
       "      <td>444.131714</td>\n",
       "      <td>0.740220</td>\n",
       "      <td>470</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>88.066604</td>\n",
       "      <td>88.543387</td>\n",
       "      <td>85.709978</td>\n",
       "      <td>86.844833</td>\n",
       "      <td>2.644760e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.183976</td>\n",
       "      <td>-0.362318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-06-20</td>\n",
       "      <td>722</td>\n",
       "      <td>540.997009</td>\n",
       "      <td>0.749303</td>\n",
       "      <td>564</td>\n",
       "      <td>0.781163</td>\n",
       "      <td>87.793445</td>\n",
       "      <td>88.783438</td>\n",
       "      <td>86.206634</td>\n",
       "      <td>87.602231</td>\n",
       "      <td>2.214657e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.228015</td>\n",
       "      <td>-0.147401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>251</td>\n",
       "      <td>187.757950</td>\n",
       "      <td>0.748040</td>\n",
       "      <td>194</td>\n",
       "      <td>0.772908</td>\n",
       "      <td>87.520286</td>\n",
       "      <td>89.023489</td>\n",
       "      <td>86.703289</td>\n",
       "      <td>88.359629</td>\n",
       "      <td>1.784555e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.528491</td>\n",
       "      <td>-0.002659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year               ∆t  Month  day  weekday       Date  body  total_score  \\\n",
       "0  2020                0      6   17        2 2020-06-17   619   486.633606   \n",
       "1  2020  1 days 00:00:00      6   18        3 2020-06-18   765   569.742188   \n",
       "2  2020  1 days 00:00:00      6   19        4 2020-06-19   600   444.131714   \n",
       "3  2020  1 days 00:00:00      6   20        5 2020-06-20   722   540.997009   \n",
       "4  2020  1 days 00:00:00      6   21        6 2020-06-21   251   187.757950   \n",
       "\n",
       "   average_score  pos_count  pos_prop       Open       High        Low  \\\n",
       "0       0.786161        519  0.838449  88.193247  88.255328  87.185041   \n",
       "1       0.744761        614  0.802614  87.264512  87.771101  86.720676   \n",
       "2       0.740220        470  0.783333  88.066604  88.543387  85.709978   \n",
       "3       0.749303        564  0.781163  87.793445  88.783438  86.206634   \n",
       "4       0.748040        194  0.772908  87.520286  89.023489  86.703289   \n",
       "\n",
       "       Close        Volume  Dividends  Stock Splits      trend  seasonal  \n",
       "0  87.309204  1.144064e+08        0.0           0.0  87.776451  0.068787  \n",
       "1  87.343979  9.682040e+07        0.0           0.0  87.980214 -0.091560  \n",
       "2  86.844833  2.644760e+08        0.0           0.0  88.183976 -0.362318  \n",
       "3  87.602231  2.214657e+08        0.0           0.0  88.228015 -0.147401  \n",
       "4  88.359629  1.784555e+08        0.0           0.0  88.528491 -0.002659  "
      ]
     },
     "execution_count": 886,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=304\n",
    "full_df = df_final.copy(deep=True)\n",
    "full_df['Date'] = pd.to_datetime(full_df.Date)\n",
    "full_df = full_df.interpolate(method='linear')\n",
    "result = seasonal_decompose(full_df[['Close']], model='additive', period=7, extrapolate_trend='freq')\n",
    "full_df['trend'] = result.trend\n",
    "full_df['seasonal'] = result.seasonal\n",
    "deltaT = np.array([(full_df.Date[i + 1] - full_df.Date[i]) for i in range(len(full_df)-1)])\n",
    "deltaT = np.concatenate((np.array([0]), deltaT))\n",
    "full_df.insert(1, '∆t', deltaT)\n",
    "full_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation of Closing price with total_score and pos_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.37375825],\n",
       "       [0.37375825, 1.        ]])"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(full_df['Close'],full_df['total_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.38442789],\n",
       "       [0.38442789, 1.        ]])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(full_df['Close'],full_df['pos_prop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.4560541],\n",
       "       [0.4560541, 1.       ]])"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(full_df['Close'],full_df['average_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.33139081],\n",
       "       [0.33139081, 1.        ]])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(full_df['Close'],full_df['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We could observe some correlation between closing price of stock and average sentiment score for that day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Time series (Forecasting stock price using past prices and sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>∆t</th>\n",
       "      <th>Month</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>Date</th>\n",
       "      <th>body</th>\n",
       "      <th>total_score</th>\n",
       "      <th>average_score</th>\n",
       "      <th>pos_count</th>\n",
       "      <th>pos_prop</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>trend</th>\n",
       "      <th>seasonal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-06-17</td>\n",
       "      <td>619</td>\n",
       "      <td>486.633606</td>\n",
       "      <td>0.786161</td>\n",
       "      <td>519</td>\n",
       "      <td>0.838449</td>\n",
       "      <td>88.193247</td>\n",
       "      <td>88.255328</td>\n",
       "      <td>87.185041</td>\n",
       "      <td>87.309204</td>\n",
       "      <td>1.144064e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.776451</td>\n",
       "      <td>0.068787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-06-18</td>\n",
       "      <td>765</td>\n",
       "      <td>569.742188</td>\n",
       "      <td>0.744761</td>\n",
       "      <td>614</td>\n",
       "      <td>0.802614</td>\n",
       "      <td>87.264512</td>\n",
       "      <td>87.771101</td>\n",
       "      <td>86.720676</td>\n",
       "      <td>87.343979</td>\n",
       "      <td>9.682040e+07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.980214</td>\n",
       "      <td>-0.091560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-06-19</td>\n",
       "      <td>600</td>\n",
       "      <td>444.131714</td>\n",
       "      <td>0.740220</td>\n",
       "      <td>470</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>88.066604</td>\n",
       "      <td>88.543387</td>\n",
       "      <td>85.709978</td>\n",
       "      <td>86.844833</td>\n",
       "      <td>2.644760e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.183976</td>\n",
       "      <td>-0.362318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-06-20</td>\n",
       "      <td>722</td>\n",
       "      <td>540.997009</td>\n",
       "      <td>0.749303</td>\n",
       "      <td>564</td>\n",
       "      <td>0.781163</td>\n",
       "      <td>87.793445</td>\n",
       "      <td>88.783438</td>\n",
       "      <td>86.206634</td>\n",
       "      <td>87.602231</td>\n",
       "      <td>2.214657e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.228015</td>\n",
       "      <td>-0.147401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>1 days 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>2020-06-21</td>\n",
       "      <td>251</td>\n",
       "      <td>187.757950</td>\n",
       "      <td>0.748040</td>\n",
       "      <td>194</td>\n",
       "      <td>0.772908</td>\n",
       "      <td>87.520286</td>\n",
       "      <td>89.023489</td>\n",
       "      <td>86.703289</td>\n",
       "      <td>88.359629</td>\n",
       "      <td>1.784555e+08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88.528491</td>\n",
       "      <td>-0.002659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year               ∆t  Month  day  weekday       Date  body  total_score  \\\n",
       "0  2020                0      6   17        2 2020-06-17   619   486.633606   \n",
       "1  2020  1 days 00:00:00      6   18        3 2020-06-18   765   569.742188   \n",
       "2  2020  1 days 00:00:00      6   19        4 2020-06-19   600   444.131714   \n",
       "3  2020  1 days 00:00:00      6   20        5 2020-06-20   722   540.997009   \n",
       "4  2020  1 days 00:00:00      6   21        6 2020-06-21   251   187.757950   \n",
       "\n",
       "   average_score  pos_count  pos_prop       Open       High        Low  \\\n",
       "0       0.786161        519  0.838449  88.193247  88.255328  87.185041   \n",
       "1       0.744761        614  0.802614  87.264512  87.771101  86.720676   \n",
       "2       0.740220        470  0.783333  88.066604  88.543387  85.709978   \n",
       "3       0.749303        564  0.781163  87.793445  88.783438  86.206634   \n",
       "4       0.748040        194  0.772908  87.520286  89.023489  86.703289   \n",
       "\n",
       "       Close        Volume  Dividends  Stock Splits      trend  seasonal  \n",
       "0  87.309204  1.144064e+08        0.0           0.0  87.776451  0.068787  \n",
       "1  87.343979  9.682040e+07        0.0           0.0  87.980214 -0.091560  \n",
       "2  86.844833  2.644760e+08        0.0           0.0  88.183976 -0.362318  \n",
       "3  87.602231  2.214657e+08        0.0           0.0  88.228015 -0.147401  \n",
       "4  88.359629  1.784555e+08        0.0           0.0  88.528491 -0.002659  "
      ]
     },
     "execution_count": 1263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_df[full_df['Date'] < '2021-03-27']\n",
    "train_dates = df['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(df[['Close','average_score']])\n",
    "df_for_training = df[cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scalar = StandardScaler()\n",
    "scalar = scalar.fit(df_for_training)\n",
    "df_for_training_scaled = scalar.transform(df_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX =[]\n",
    "trainY =[]\n",
    "n_future =1\n",
    "n_past = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n_past, len(df_for_training_scaled) -n_future+1):\n",
    "    trainX.append(df_for_training_scaled[i-n_past:i,0:df_for_training.shape[1]])\n",
    "    trainY.append(df_for_training_scaled[i+n_future - 1:i+n_future,0])\n",
    "trainX, trainY = np.array(trainX), np.array(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255, 28, 2)\n",
      "(255, 1)\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape)\n",
    "print(trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "8/8 [==============================] - 0s 46ms/step - loss: 0.3397 - mae: 0.6789 - val_loss: 0.0802 - val_mae: 0.3622\n",
      "Epoch 2/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3389 - mae: 0.6780 - val_loss: 0.0795 - val_mae: 0.3605\n",
      "Epoch 3/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3375 - mae: 0.6765 - val_loss: 0.0786 - val_mae: 0.3581\n",
      "Epoch 4/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3359 - mae: 0.6748 - val_loss: 0.0777 - val_mae: 0.3557\n",
      "Epoch 5/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3343 - mae: 0.6731 - val_loss: 0.0766 - val_mae: 0.3529\n",
      "Epoch 6/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3324 - mae: 0.6712 - val_loss: 0.0757 - val_mae: 0.3503\n",
      "Epoch 7/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3307 - mae: 0.6694 - val_loss: 0.0747 - val_mae: 0.3478\n",
      "Epoch 8/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3289 - mae: 0.6675 - val_loss: 0.0739 - val_mae: 0.3454\n",
      "Epoch 9/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3272 - mae: 0.6657 - val_loss: 0.0730 - val_mae: 0.3431\n",
      "Epoch 10/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3256 - mae: 0.6640 - val_loss: 0.0721 - val_mae: 0.3406\n",
      "Epoch 11/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3238 - mae: 0.6620 - val_loss: 0.0714 - val_mae: 0.3386\n",
      "Epoch 12/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3222 - mae: 0.6603 - val_loss: 0.0706 - val_mae: 0.3363\n",
      "Epoch 13/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3205 - mae: 0.6584 - val_loss: 0.0698 - val_mae: 0.3340\n",
      "Epoch 14/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3188 - mae: 0.6566 - val_loss: 0.0690 - val_mae: 0.3319\n",
      "Epoch 15/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3172 - mae: 0.6548 - val_loss: 0.0683 - val_mae: 0.3298\n",
      "Epoch 16/400\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3155 - mae: 0.6529 - val_loss: 0.0676 - val_mae: 0.3280\n",
      "Epoch 17/400\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3139 - mae: 0.6512 - val_loss: 0.0669 - val_mae: 0.3258\n",
      "Epoch 18/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3123 - mae: 0.6493 - val_loss: 0.0663 - val_mae: 0.3240\n",
      "Epoch 19/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3107 - mae: 0.6477 - val_loss: 0.0656 - val_mae: 0.3219\n",
      "Epoch 20/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3092 - mae: 0.6460 - val_loss: 0.0648 - val_mae: 0.3197\n",
      "Epoch 21/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.3076 - mae: 0.6442 - val_loss: 0.0641 - val_mae: 0.3177\n",
      "Epoch 22/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3061 - mae: 0.6425 - val_loss: 0.0635 - val_mae: 0.3159\n",
      "Epoch 23/400\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3045 - mae: 0.6408 - val_loss: 0.0628 - val_mae: 0.3136\n",
      "Epoch 24/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3029 - mae: 0.6391 - val_loss: 0.0620 - val_mae: 0.3114\n",
      "Epoch 25/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3015 - mae: 0.6374 - val_loss: 0.0615 - val_mae: 0.3097\n",
      "Epoch 26/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.3001 - mae: 0.6359 - val_loss: 0.0609 - val_mae: 0.3078\n",
      "Epoch 27/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2988 - mae: 0.6343 - val_loss: 0.0603 - val_mae: 0.3059\n",
      "Epoch 28/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2974 - mae: 0.6328 - val_loss: 0.0598 - val_mae: 0.3043\n",
      "Epoch 29/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2961 - mae: 0.6313 - val_loss: 0.0592 - val_mae: 0.3025\n",
      "Epoch 30/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2948 - mae: 0.6299 - val_loss: 0.0586 - val_mae: 0.3007\n",
      "Epoch 31/400\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2936 - mae: 0.6286 - val_loss: 0.0580 - val_mae: 0.2988\n",
      "Epoch 32/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2924 - mae: 0.6272 - val_loss: 0.0575 - val_mae: 0.2970\n",
      "Epoch 33/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2911 - mae: 0.6258 - val_loss: 0.0569 - val_mae: 0.2951\n",
      "Epoch 34/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2898 - mae: 0.6242 - val_loss: 0.0564 - val_mae: 0.2934\n",
      "Epoch 35/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2885 - mae: 0.6228 - val_loss: 0.0558 - val_mae: 0.2915\n",
      "Epoch 36/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2872 - mae: 0.6213 - val_loss: 0.0553 - val_mae: 0.2900\n",
      "Epoch 37/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2860 - mae: 0.6199 - val_loss: 0.0550 - val_mae: 0.2889\n",
      "Epoch 38/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2848 - mae: 0.6184 - val_loss: 0.0547 - val_mae: 0.2880\n",
      "Epoch 39/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2835 - mae: 0.6169 - val_loss: 0.0544 - val_mae: 0.2868\n",
      "Epoch 40/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2823 - mae: 0.6154 - val_loss: 0.0539 - val_mae: 0.2854\n",
      "Epoch 41/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2810 - mae: 0.6140 - val_loss: 0.0533 - val_mae: 0.2834\n",
      "Epoch 42/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2797 - mae: 0.6125 - val_loss: 0.0527 - val_mae: 0.2814\n",
      "Epoch 43/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2784 - mae: 0.6110 - val_loss: 0.0522 - val_mae: 0.2798\n",
      "Epoch 44/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2771 - mae: 0.6096 - val_loss: 0.0517 - val_mae: 0.2781\n",
      "Epoch 45/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2759 - mae: 0.6081 - val_loss: 0.0512 - val_mae: 0.2767\n",
      "Epoch 46/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2746 - mae: 0.6066 - val_loss: 0.0507 - val_mae: 0.2750\n",
      "Epoch 47/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2733 - mae: 0.6051 - val_loss: 0.0502 - val_mae: 0.2734\n",
      "Epoch 48/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2721 - mae: 0.6037 - val_loss: 0.0498 - val_mae: 0.2721\n",
      "Epoch 49/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2708 - mae: 0.6021 - val_loss: 0.0494 - val_mae: 0.2709\n",
      "Epoch 50/400\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2696 - mae: 0.6007 - val_loss: 0.0490 - val_mae: 0.2694\n",
      "Epoch 51/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2684 - mae: 0.5992 - val_loss: 0.0486 - val_mae: 0.2682\n",
      "Epoch 52/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2671 - mae: 0.5977 - val_loss: 0.0482 - val_mae: 0.2668\n",
      "Epoch 53/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2659 - mae: 0.5962 - val_loss: 0.0477 - val_mae: 0.2652\n",
      "Epoch 54/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2647 - mae: 0.5948 - val_loss: 0.0472 - val_mae: 0.2633\n",
      "Epoch 55/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2634 - mae: 0.5932 - val_loss: 0.0466 - val_mae: 0.2614\n",
      "Epoch 56/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2621 - mae: 0.5917 - val_loss: 0.0462 - val_mae: 0.2599\n",
      "Epoch 57/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2609 - mae: 0.5902 - val_loss: 0.0458 - val_mae: 0.2586\n",
      "Epoch 58/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2596 - mae: 0.5887 - val_loss: 0.0453 - val_mae: 0.2569\n",
      "Epoch 59/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2584 - mae: 0.5872 - val_loss: 0.0449 - val_mae: 0.2556\n",
      "Epoch 60/400\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2572 - mae: 0.5858 - val_loss: 0.0446 - val_mae: 0.2543\n",
      "Epoch 61/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2561 - mae: 0.5843 - val_loss: 0.0441 - val_mae: 0.2528\n",
      "Epoch 62/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2548 - mae: 0.5828 - val_loss: 0.0437 - val_mae: 0.2513\n",
      "Epoch 63/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2536 - mae: 0.5813 - val_loss: 0.0433 - val_mae: 0.2498\n",
      "Epoch 64/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2524 - mae: 0.5799 - val_loss: 0.0429 - val_mae: 0.2484\n",
      "Epoch 65/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2512 - mae: 0.5784 - val_loss: 0.0426 - val_mae: 0.2471\n",
      "Epoch 66/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2501 - mae: 0.5769 - val_loss: 0.0423 - val_mae: 0.2460\n",
      "Epoch 67/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2489 - mae: 0.5754 - val_loss: 0.0420 - val_mae: 0.2450\n",
      "Epoch 68/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2478 - mae: 0.5740 - val_loss: 0.0417 - val_mae: 0.2440\n",
      "Epoch 69/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2466 - mae: 0.5725 - val_loss: 0.0415 - val_mae: 0.2429\n",
      "Epoch 70/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2455 - mae: 0.5710 - val_loss: 0.0411 - val_mae: 0.2415\n",
      "Epoch 71/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2443 - mae: 0.5695 - val_loss: 0.0407 - val_mae: 0.2402\n",
      "Epoch 72/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2431 - mae: 0.5680 - val_loss: 0.0404 - val_mae: 0.2388\n",
      "Epoch 73/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2419 - mae: 0.5665 - val_loss: 0.0400 - val_mae: 0.2373\n",
      "Epoch 74/400\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2406 - mae: 0.5649 - val_loss: 0.0395 - val_mae: 0.2355\n",
      "Epoch 75/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2393 - mae: 0.5633 - val_loss: 0.0390 - val_mae: 0.2336\n",
      "Epoch 76/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2380 - mae: 0.5616 - val_loss: 0.0386 - val_mae: 0.2321\n",
      "Epoch 77/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2369 - mae: 0.5602 - val_loss: 0.0382 - val_mae: 0.2302\n",
      "Epoch 78/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2356 - mae: 0.5585 - val_loss: 0.0378 - val_mae: 0.2288\n",
      "Epoch 79/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2344 - mae: 0.5570 - val_loss: 0.0374 - val_mae: 0.2271\n",
      "Epoch 80/400\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2332 - mae: 0.5554 - val_loss: 0.0370 - val_mae: 0.2255\n",
      "Epoch 81/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2319 - mae: 0.5538 - val_loss: 0.0366 - val_mae: 0.2237\n",
      "Epoch 82/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2307 - mae: 0.5522 - val_loss: 0.0362 - val_mae: 0.2220\n",
      "Epoch 83/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2294 - mae: 0.5506 - val_loss: 0.0357 - val_mae: 0.2202\n",
      "Epoch 84/400\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.2282 - mae: 0.5490 - val_loss: 0.0354 - val_mae: 0.2186\n",
      "Epoch 85/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2270 - mae: 0.5475 - val_loss: 0.0351 - val_mae: 0.2173\n",
      "Epoch 86/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2258 - mae: 0.5458 - val_loss: 0.0348 - val_mae: 0.2162\n",
      "Epoch 87/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2246 - mae: 0.5442 - val_loss: 0.0346 - val_mae: 0.2150\n",
      "Epoch 88/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2234 - mae: 0.5425 - val_loss: 0.0342 - val_mae: 0.2136\n",
      "Epoch 89/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2222 - mae: 0.5410 - val_loss: 0.0339 - val_mae: 0.2120\n",
      "Epoch 90/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2209 - mae: 0.5393 - val_loss: 0.0337 - val_mae: 0.2110\n",
      "Epoch 91/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2197 - mae: 0.5376 - val_loss: 0.0334 - val_mae: 0.2100\n",
      "Epoch 92/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2185 - mae: 0.5360 - val_loss: 0.0332 - val_mae: 0.2089\n",
      "Epoch 93/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2172 - mae: 0.5343 - val_loss: 0.0329 - val_mae: 0.2077\n",
      "Epoch 94/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2159 - mae: 0.5327 - val_loss: 0.0327 - val_mae: 0.2064\n",
      "Epoch 95/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2147 - mae: 0.5310 - val_loss: 0.0324 - val_mae: 0.2052\n",
      "Epoch 96/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2135 - mae: 0.5294 - val_loss: 0.0322 - val_mae: 0.2040\n",
      "Epoch 97/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2122 - mae: 0.5277 - val_loss: 0.0318 - val_mae: 0.2025\n",
      "Epoch 98/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2110 - mae: 0.5261 - val_loss: 0.0316 - val_mae: 0.2013\n",
      "Epoch 99/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2098 - mae: 0.5244 - val_loss: 0.0313 - val_mae: 0.2001\n",
      "Epoch 100/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2084 - mae: 0.5226 - val_loss: 0.0309 - val_mae: 0.1986\n",
      "Epoch 101/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2071 - mae: 0.5208 - val_loss: 0.0307 - val_mae: 0.1974\n",
      "Epoch 102/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2058 - mae: 0.5191 - val_loss: 0.0304 - val_mae: 0.1961\n",
      "Epoch 103/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2045 - mae: 0.5172 - val_loss: 0.0301 - val_mae: 0.1947\n",
      "Epoch 104/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.2032 - mae: 0.5154 - val_loss: 0.0297 - val_mae: 0.1932\n",
      "Epoch 105/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2018 - mae: 0.5135 - val_loss: 0.0295 - val_mae: 0.1920\n",
      "Epoch 106/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.2005 - mae: 0.5116 - val_loss: 0.0292 - val_mae: 0.1906\n",
      "Epoch 107/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1991 - mae: 0.5097 - val_loss: 0.0289 - val_mae: 0.1894\n",
      "Epoch 108/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1978 - mae: 0.5080 - val_loss: 0.0287 - val_mae: 0.1887\n",
      "Epoch 109/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1966 - mae: 0.5061 - val_loss: 0.0284 - val_mae: 0.1876\n",
      "Epoch 110/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1952 - mae: 0.5042 - val_loss: 0.0282 - val_mae: 0.1866\n",
      "Epoch 111/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1939 - mae: 0.5024 - val_loss: 0.0279 - val_mae: 0.1856\n",
      "Epoch 112/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1925 - mae: 0.5004 - val_loss: 0.0276 - val_mae: 0.1845\n",
      "Epoch 113/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1911 - mae: 0.4984 - val_loss: 0.0274 - val_mae: 0.1838\n",
      "Epoch 114/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1898 - mae: 0.4965 - val_loss: 0.0272 - val_mae: 0.1832\n",
      "Epoch 115/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1885 - mae: 0.4945 - val_loss: 0.0270 - val_mae: 0.1824\n",
      "Epoch 116/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1871 - mae: 0.4927 - val_loss: 0.0268 - val_mae: 0.1816\n",
      "Epoch 117/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1858 - mae: 0.4907 - val_loss: 0.0266 - val_mae: 0.1809\n",
      "Epoch 118/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1844 - mae: 0.4887 - val_loss: 0.0264 - val_mae: 0.1801\n",
      "Epoch 119/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1830 - mae: 0.4866 - val_loss: 0.0263 - val_mae: 0.1793\n",
      "Epoch 120/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1816 - mae: 0.4845 - val_loss: 0.0260 - val_mae: 0.1785\n",
      "Epoch 121/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1801 - mae: 0.4823 - val_loss: 0.0259 - val_mae: 0.1780\n",
      "Epoch 122/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1787 - mae: 0.4802 - val_loss: 0.0258 - val_mae: 0.1775\n",
      "Epoch 123/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1772 - mae: 0.4780 - val_loss: 0.0256 - val_mae: 0.1770\n",
      "Epoch 124/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1758 - mae: 0.4758 - val_loss: 0.0253 - val_mae: 0.1763\n",
      "Epoch 125/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1742 - mae: 0.4735 - val_loss: 0.0251 - val_mae: 0.1756\n",
      "Epoch 126/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1727 - mae: 0.4711 - val_loss: 0.0250 - val_mae: 0.1752\n",
      "Epoch 127/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1712 - mae: 0.4689 - val_loss: 0.0248 - val_mae: 0.1747\n",
      "Epoch 128/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1698 - mae: 0.4666 - val_loss: 0.0246 - val_mae: 0.1740\n",
      "Epoch 129/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1682 - mae: 0.4643 - val_loss: 0.0243 - val_mae: 0.1732\n",
      "Epoch 130/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1666 - mae: 0.4619 - val_loss: 0.0241 - val_mae: 0.1724\n",
      "Epoch 131/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1652 - mae: 0.4595 - val_loss: 0.0239 - val_mae: 0.1718\n",
      "Epoch 132/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1636 - mae: 0.4572 - val_loss: 0.0237 - val_mae: 0.1711\n",
      "Epoch 133/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1622 - mae: 0.4549 - val_loss: 0.0235 - val_mae: 0.1705\n",
      "Epoch 134/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1606 - mae: 0.4524 - val_loss: 0.0233 - val_mae: 0.1699\n",
      "Epoch 135/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1591 - mae: 0.4501 - val_loss: 0.0232 - val_mae: 0.1693\n",
      "Epoch 136/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1576 - mae: 0.4478 - val_loss: 0.0229 - val_mae: 0.1686\n",
      "Epoch 137/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1560 - mae: 0.4452 - val_loss: 0.0228 - val_mae: 0.1681\n",
      "Epoch 138/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1545 - mae: 0.4429 - val_loss: 0.0226 - val_mae: 0.1674\n",
      "Epoch 139/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1529 - mae: 0.4404 - val_loss: 0.0225 - val_mae: 0.1669\n",
      "Epoch 140/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1512 - mae: 0.4378 - val_loss: 0.0223 - val_mae: 0.1663\n",
      "Epoch 141/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1497 - mae: 0.4354 - val_loss: 0.0221 - val_mae: 0.1657\n",
      "Epoch 142/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1481 - mae: 0.4328 - val_loss: 0.0220 - val_mae: 0.1651\n",
      "Epoch 143/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1465 - mae: 0.4303 - val_loss: 0.0218 - val_mae: 0.1645\n",
      "Epoch 144/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1448 - mae: 0.4277 - val_loss: 0.0216 - val_mae: 0.1637\n",
      "Epoch 145/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1431 - mae: 0.4249 - val_loss: 0.0214 - val_mae: 0.1630\n",
      "Epoch 146/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1414 - mae: 0.4221 - val_loss: 0.0213 - val_mae: 0.1627\n",
      "Epoch 147/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1395 - mae: 0.4192 - val_loss: 0.0212 - val_mae: 0.1620\n",
      "Epoch 148/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1377 - mae: 0.4163 - val_loss: 0.0210 - val_mae: 0.1613\n",
      "Epoch 149/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1360 - mae: 0.4135 - val_loss: 0.0208 - val_mae: 0.1606\n",
      "Epoch 150/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1342 - mae: 0.4105 - val_loss: 0.0207 - val_mae: 0.1599\n",
      "Epoch 151/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1326 - mae: 0.4078 - val_loss: 0.0205 - val_mae: 0.1592\n",
      "Epoch 152/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1308 - mae: 0.4048 - val_loss: 0.0203 - val_mae: 0.1585\n",
      "Epoch 153/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1290 - mae: 0.4018 - val_loss: 0.0202 - val_mae: 0.1581\n",
      "Epoch 154/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1271 - mae: 0.3986 - val_loss: 0.0202 - val_mae: 0.1580\n",
      "Epoch 155/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1252 - mae: 0.3954 - val_loss: 0.0202 - val_mae: 0.1581\n",
      "Epoch 156/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1234 - mae: 0.3921 - val_loss: 0.0201 - val_mae: 0.1579\n",
      "Epoch 157/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1215 - mae: 0.3889 - val_loss: 0.0200 - val_mae: 0.1575\n",
      "Epoch 158/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1199 - mae: 0.3859 - val_loss: 0.0198 - val_mae: 0.1570\n",
      "Epoch 159/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1182 - mae: 0.3828 - val_loss: 0.0197 - val_mae: 0.1564\n",
      "Epoch 160/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1166 - mae: 0.3799 - val_loss: 0.0196 - val_mae: 0.1561\n",
      "Epoch 161/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1147 - mae: 0.3766 - val_loss: 0.0195 - val_mae: 0.1558\n",
      "Epoch 162/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1131 - mae: 0.3733 - val_loss: 0.0194 - val_mae: 0.1554\n",
      "Epoch 163/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1114 - mae: 0.3702 - val_loss: 0.0193 - val_mae: 0.1550\n",
      "Epoch 164/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1097 - mae: 0.3671 - val_loss: 0.0192 - val_mae: 0.1546\n",
      "Epoch 165/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1080 - mae: 0.3637 - val_loss: 0.0190 - val_mae: 0.1543\n",
      "Epoch 166/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1062 - mae: 0.3600 - val_loss: 0.0188 - val_mae: 0.1539\n",
      "Epoch 167/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.1044 - mae: 0.3565 - val_loss: 0.0187 - val_mae: 0.1535\n",
      "Epoch 168/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1027 - mae: 0.3532 - val_loss: 0.0185 - val_mae: 0.1531\n",
      "Epoch 169/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.1011 - mae: 0.3501 - val_loss: 0.0184 - val_mae: 0.1528\n",
      "Epoch 170/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0996 - mae: 0.3471 - val_loss: 0.0183 - val_mae: 0.1526\n",
      "Epoch 171/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0981 - mae: 0.3441 - val_loss: 0.0182 - val_mae: 0.1526\n",
      "Epoch 172/400\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0966 - mae: 0.3414 - val_loss: 0.0182 - val_mae: 0.1527\n",
      "Epoch 173/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0949 - mae: 0.3385 - val_loss: 0.0182 - val_mae: 0.1530\n",
      "Epoch 174/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0932 - mae: 0.3356 - val_loss: 0.0182 - val_mae: 0.1533\n",
      "Epoch 175/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0915 - mae: 0.3331 - val_loss: 0.0182 - val_mae: 0.1534\n",
      "Epoch 176/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0900 - mae: 0.3306 - val_loss: 0.0181 - val_mae: 0.1535\n",
      "Epoch 177/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0885 - mae: 0.3280 - val_loss: 0.0180 - val_mae: 0.1535\n",
      "Epoch 178/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0870 - mae: 0.3254 - val_loss: 0.0179 - val_mae: 0.1534\n",
      "Epoch 179/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0858 - mae: 0.3232 - val_loss: 0.0179 - val_mae: 0.1534\n",
      "Epoch 180/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0844 - mae: 0.3207 - val_loss: 0.0178 - val_mae: 0.1534\n",
      "Epoch 181/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0832 - mae: 0.3186 - val_loss: 0.0177 - val_mae: 0.1534\n",
      "Epoch 182/400\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0821 - mae: 0.3164 - val_loss: 0.0177 - val_mae: 0.1535\n",
      "Epoch 183/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0809 - mae: 0.3143 - val_loss: 0.0176 - val_mae: 0.1535\n",
      "Epoch 184/400\n",
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0797 - mae: 0.3119 - val_loss: 0.0176 - val_mae: 0.1534\n",
      "Epoch 185/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0785 - mae: 0.3098 - val_loss: 0.0175 - val_mae: 0.1534\n",
      "Epoch 186/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0774 - mae: 0.3075 - val_loss: 0.0175 - val_mae: 0.1535\n",
      "Epoch 187/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 0.0761 - mae: 0.3053 - val_loss: 0.0174 - val_mae: 0.1536\n",
      "Epoch 188/400\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0751 - mae: 0.3034 - val_loss: 0.0174 - val_mae: 0.1536\n",
      "Epoch 189/400\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0743 - mae: 0.3016 - val_loss: 0.0173 - val_mae: 0.1537\n",
      "Epoch 190/400\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0734 - mae: 0.3000 - val_loss: 0.0173 - val_mae: 0.1537\n",
      "Epoch 191/400\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0726 - mae: 0.2983 - val_loss: 0.0172 - val_mae: 0.1537\n",
      "Epoch 192/400\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0719 - mae: 0.2966 - val_loss: 0.0172 - val_mae: 0.1537\n",
      "Epoch 193/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0711 - mae: 0.2949 - val_loss: 0.0172 - val_mae: 0.1537\n",
      "Epoch 194/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0704 - mae: 0.2935 - val_loss: 0.0172 - val_mae: 0.1538\n",
      "Epoch 195/400\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0699 - mae: 0.2922 - val_loss: 0.0171 - val_mae: 0.1538\n",
      "Epoch 196/400\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0692 - mae: 0.2905 - val_loss: 0.0171 - val_mae: 0.1538\n",
      "Epoch 197/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0686 - mae: 0.2892 - val_loss: 0.0171 - val_mae: 0.1538\n",
      "Epoch 198/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0680 - mae: 0.2876 - val_loss: 0.0171 - val_mae: 0.1539\n",
      "Epoch 199/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0672 - mae: 0.2860 - val_loss: 0.0171 - val_mae: 0.1541\n",
      "Epoch 200/400\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0667 - mae: 0.2850 - val_loss: 0.0171 - val_mae: 0.1542\n",
      "Epoch 201/400\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0663 - mae: 0.2839 - val_loss: 0.0171 - val_mae: 0.1542\n",
      "Epoch 202/400\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0659 - mae: 0.2827 - val_loss: 0.0171 - val_mae: 0.1542\n",
      "Epoch 203/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0657 - mae: 0.2818 - val_loss: 0.0171 - val_mae: 0.1542\n",
      "Epoch 204/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0654 - mae: 0.2809 - val_loss: 0.0171 - val_mae: 0.1541\n",
      "Epoch 205/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0651 - mae: 0.2800 - val_loss: 0.0172 - val_mae: 0.1541\n",
      "Epoch 206/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0649 - mae: 0.2792 - val_loss: 0.0172 - val_mae: 0.1541\n",
      "Epoch 207/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0647 - mae: 0.2786 - val_loss: 0.0172 - val_mae: 0.1542\n",
      "Epoch 208/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0645 - mae: 0.2781 - val_loss: 0.0172 - val_mae: 0.1542\n",
      "Epoch 209/400\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0643 - mae: 0.2773 - val_loss: 0.0172 - val_mae: 0.1541\n",
      "Epoch 210/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0641 - mae: 0.2767 - val_loss: 0.0172 - val_mae: 0.1540\n",
      "Epoch 211/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0639 - mae: 0.2761 - val_loss: 0.0173 - val_mae: 0.1540\n",
      "Epoch 212/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0638 - mae: 0.2756 - val_loss: 0.0173 - val_mae: 0.1540\n",
      "Epoch 213/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0636 - mae: 0.2751 - val_loss: 0.0173 - val_mae: 0.1539\n",
      "Epoch 214/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0635 - mae: 0.2746 - val_loss: 0.0173 - val_mae: 0.1540\n",
      "Epoch 215/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0634 - mae: 0.2740 - val_loss: 0.0174 - val_mae: 0.1542\n",
      "Epoch 216/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0633 - mae: 0.2737 - val_loss: 0.0174 - val_mae: 0.1543\n",
      "Epoch 217/400\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0632 - mae: 0.2734 - val_loss: 0.0174 - val_mae: 0.1545\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(LSTM(64, activation=\"relu\", input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation=\"relu\", return_sequences=False))\n",
    "model.add(Dense(trainY.shape[1]))\n",
    "optimizer = tf.keras.optimizers.SGD(lr=1e-4, momentum=0.9)\n",
    "model.compile(loss=tf.keras.losses.Huber(),\n",
    "              optimizer=optimizer,\n",
    "              metrics=[\"mae\"])\n",
    "history = model.fit(trainX, trainY, epochs=400, validation_split=0.1, verbose =1, callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1280,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future = 28\n",
    "forecast_period_dates = pd.date_range(list(train_dates)[-1], periods= n_future, freq = '1d').tolist()\n",
    "forecast = model.predict(trainX[-n_future:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the shape of forecasted array to Xtrain shape to unscale the prediction\n",
    "forecast_copies = np.repeat(forecast, df_for_training.shape[1], axis =-1)\n",
    "y_pred_future = scalar.inverse_transform(forecast_copies)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.7396674\n"
     ]
    }
   ],
   "source": [
    "error = tf.keras.metrics.mean_absolute_error(full_df['Close'][-28:], y_pred_future).numpy()\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Forecasetd price vs actual price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x267a6f26e80>]"
      ]
     },
     "execution_count": 1287,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 6)) \n",
    "price_date = full_df['Date']\n",
    "price_close = full_df['Close']\n",
    "\n",
    "plt.plot_date(price_date, price_close, linestyle='solid',color='k')\n",
    "\n",
    "price_date_2 = full_df['Date'][len(full_df)-len(y_pred_future):]\n",
    "price_close_2 = y_pred_future\n",
    "plt.plot_date(price_date_2, price_close_2, linestyle='solid',color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the plot we could see that the predictions from our model are not very accurate. One of the main reason for this could be \n",
    "### 1. lesser data points. The final multivriate time series model had only 250 data points in the train set\n",
    "### 2. Given the lesser data points, a simple logistic regression model might yield better results\n",
    "### 3. We could see that daily average sentiment score had some correlation (0.45) with the closing price. However, relying only on stock_twits for sentiment may not be giving us the actual sentiment. We should also try to include sentiment from other sources such as news headlines, twitter, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
